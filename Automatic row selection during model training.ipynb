{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic row selection during model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A lot of time is spent during model training engineering and selecting features. \n",
    "\n",
    "*However, in a dataset there can be not only column-wise noise but also row-wise noise. There can be rows where the information collected is of bad quality and they can worsen the model trained through forcing the model to overfit the noise to reduce the error. This overfitting creates less generalizable models.\n",
    "\n",
    "*It is good to have as much data as possible but it is also  necessary to find the right balance between amount and quality of data. There are some methods to preprocess data to reduce this noise or to find rows behaving as outliers (and then should be removed). However, these methods would need the onehot encoding of categorical data (with its caveats) and they seem not to be usable in non-tabular data (e.g. for image selection).\n",
    "\n",
    "*Some methods of feature selection are based on achieving information during model training to decide which features to keep or not. However, as far as I am concerned, there are no methods to try to take advantage in an automatic manner of the information collected during model training. Probably this is caused by the lack of reliability of the residuals found during model training (because of the overfitting of noise).\n",
    "\n",
    "*However, if one performs bootstrapping during model training and saves the predictions, one can analyze in which rows the prediction will be of worse quality. If for all bootstrap iterations the prediction was of bad quality, this will be an indicator that the prediction is failing not because of the bad model quality but because thsi row does not behave  as most other ones. Hence, this row is noisy and its removal might benefit the quality of the models achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: lattice\n",
      "Loading required package: ggplot2\n",
      "\n",
      "Attaching package: 'dplyr'\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(caret)\n",
    "library(mlbench)\n",
    "library(dplyr)\n",
    "data(BostonHousing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of training split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1);train_ind=createDataPartition(BostonHousing$medv, p=0.75)[[1]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of model with .632 bootstrap with 1000 iterations, saving all predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1);model <- train(medv ~ . ,\n",
    "               data = BostonHousing[train_ind,],\n",
    "               preProcess = c(\"center\", \"scale\"),\n",
    "               method = \"lasso\",\n",
    "               metric=\"MAE\",\n",
    "               tuneLength = 10,\n",
    "               trControl = trainControl(method = \"boot632\",number=1000,\n",
    "                                        savePredictions = \"all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "3.39731212927178"
      ],
      "text/latex": [
       "3.39731212927178"
      ],
      "text/markdown": [
       "3.39731212927178"
      ],
      "text/plain": [
       "[1] 3.397312"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAE(pred = predict(model,BostonHousing[-train_ind,]),obs=BostonHousing$medv[-train_ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Row selection according to bootstrapping information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In each the bootstrap iteration during model training, a subset of rows is selected to predict in the other subset of rows.\n",
    "\n",
    "* Theoretically, trained models during each bootstrapping iteration should be highly similar as they are analyzing similar information. If there are rows where the error estimated during prediction tends to be high, it is probable that the error is not caused by the model but by the noise present in the data in the row.\n",
    "\n",
    "* Removing rows with high error during prediction might improve models. Less noise is present in the training data then model optimization can focus better on the right weighting of the informative features and can avoid the overfititng of noise. As aresult, the models trained can be more generalizable to test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Calculation of residual between predicted and observed value during all bootstrapping iterations.\n",
    "2. Calculation of mean residual for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    rowIndex        mean               sd        \n",
       " Min.   :  1   Min.   : 0.5519   Min.   :0.3891  \n",
       " 1st Qu.: 96   1st Qu.: 1.6584   1st Qu.:0.8293  \n",
       " Median :191   Median : 2.6968   Median :1.3508  \n",
       " Mean   :191   Mean   : 3.9218   Mean   :1.6558  \n",
       " 3rd Qu.:286   3rd Qu.: 4.5555   3rd Qu.:2.0971  \n",
       " Max.   :381   Max.   :29.5058   Max.   :6.2696  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model$pred$MAE=abs(model$pred$pred-model$pred$obs)\n",
    "\n",
    "bootstrap_residual_stats = model$pred %>%\n",
    "group_by(rowIndex) %>%\n",
    "summarise(mean = mean(MAE,na.rm=T),sd=sd(MAE,na.rm=T))\n",
    "summary(bootstrap_residual_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function which estimates MAE in test split depending on the rows selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr <- function(x) {\n",
    "   set.seed(1);model=train(medv ~ . ,\n",
    "                             data = BostonHousing[train_ind,][error_order[1:x],],\n",
    "                             preProcess = c(\"center\", \"scale\"),\n",
    "                             method = \"lasso\",\n",
    "                             metric=\"MAE\",\n",
    "                             tuneLength = 10,\n",
    "                             trControl = trainControl(method = \"boot632\",\n",
    "                                                      savePredictions = \"all\"))\n",
    "  MAE(pred = predict(model,BostonHousing[-train_ind,]),obs=BostonHousing$medv[-train_ind])\n",
    "  \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparation of sequence of number of rows to use during model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_rows_sequence=seq(length(train_ind),length(train_ind)-100,-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Ordering of rows depending on MAE calculated for each row in bootstrap iterations.\n",
    "2. Calculation of MAE in test split depending on number of rows selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>no_rows_sequence</th><th scope=col>res_bootstrap</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>381     </td><td>3.416829</td></tr>\n",
       "\t<tr><td>376     </td><td>3.221369</td></tr>\n",
       "\t<tr><td>371     </td><td>3.163316</td></tr>\n",
       "\t<tr><td>366     </td><td>3.150572</td></tr>\n",
       "\t<tr><td>361     </td><td>3.137695</td></tr>\n",
       "\t<tr><td>356     </td><td>3.169770</td></tr>\n",
       "\t<tr><td>351     </td><td>3.157869</td></tr>\n",
       "\t<tr><td>346     </td><td>3.160220</td></tr>\n",
       "\t<tr><td>341     </td><td>3.194731</td></tr>\n",
       "\t<tr><td>336     </td><td>3.174838</td></tr>\n",
       "\t<tr><td>331     </td><td>3.212522</td></tr>\n",
       "\t<tr><td>326     </td><td>3.220899</td></tr>\n",
       "\t<tr><td>321     </td><td>3.271510</td></tr>\n",
       "\t<tr><td>316     </td><td>3.275932</td></tr>\n",
       "\t<tr><td>311     </td><td>3.273184</td></tr>\n",
       "\t<tr><td>306     </td><td>3.275781</td></tr>\n",
       "\t<tr><td>301     </td><td>3.250429</td></tr>\n",
       "\t<tr><td>296     </td><td>3.223305</td></tr>\n",
       "\t<tr><td>291     </td><td>3.198713</td></tr>\n",
       "\t<tr><td>286     </td><td>3.190635</td></tr>\n",
       "\t<tr><td>281     </td><td>3.181345</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{ll}\n",
       " no\\_rows\\_sequence & res\\_bootstrap\\\\\n",
       "\\hline\n",
       "\t 381      & 3.416829\\\\\n",
       "\t 376      & 3.221369\\\\\n",
       "\t 371      & 3.163316\\\\\n",
       "\t 366      & 3.150572\\\\\n",
       "\t 361      & 3.137695\\\\\n",
       "\t 356      & 3.169770\\\\\n",
       "\t 351      & 3.157869\\\\\n",
       "\t 346      & 3.160220\\\\\n",
       "\t 341      & 3.194731\\\\\n",
       "\t 336      & 3.174838\\\\\n",
       "\t 331      & 3.212522\\\\\n",
       "\t 326      & 3.220899\\\\\n",
       "\t 321      & 3.271510\\\\\n",
       "\t 316      & 3.275932\\\\\n",
       "\t 311      & 3.273184\\\\\n",
       "\t 306      & 3.275781\\\\\n",
       "\t 301      & 3.250429\\\\\n",
       "\t 296      & 3.223305\\\\\n",
       "\t 291      & 3.198713\\\\\n",
       "\t 286      & 3.190635\\\\\n",
       "\t 281      & 3.181345\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "no_rows_sequence | res_bootstrap | \n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 381      | 3.416829 | \n",
       "| 376      | 3.221369 | \n",
       "| 371      | 3.163316 | \n",
       "| 366      | 3.150572 | \n",
       "| 361      | 3.137695 | \n",
       "| 356      | 3.169770 | \n",
       "| 351      | 3.157869 | \n",
       "| 346      | 3.160220 | \n",
       "| 341      | 3.194731 | \n",
       "| 336      | 3.174838 | \n",
       "| 331      | 3.212522 | \n",
       "| 326      | 3.220899 | \n",
       "| 321      | 3.271510 | \n",
       "| 316      | 3.275932 | \n",
       "| 311      | 3.273184 | \n",
       "| 306      | 3.275781 | \n",
       "| 301      | 3.250429 | \n",
       "| 296      | 3.223305 | \n",
       "| 291      | 3.198713 | \n",
       "| 286      | 3.190635 | \n",
       "| 281      | 3.181345 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "      no_rows_sequence res_bootstrap\n",
       " [1,] 381              3.416829     \n",
       " [2,] 376              3.221369     \n",
       " [3,] 371              3.163316     \n",
       " [4,] 366              3.150572     \n",
       " [5,] 361              3.137695     \n",
       " [6,] 356              3.169770     \n",
       " [7,] 351              3.157869     \n",
       " [8,] 346              3.160220     \n",
       " [9,] 341              3.194731     \n",
       "[10,] 336              3.174838     \n",
       "[11,] 331              3.212522     \n",
       "[12,] 326              3.220899     \n",
       "[13,] 321              3.271510     \n",
       "[14,] 316              3.275932     \n",
       "[15,] 311              3.273184     \n",
       "[16,] 306              3.275781     \n",
       "[17,] 301              3.250429     \n",
       "[18,] 296              3.223305     \n",
       "[19,] 291              3.198713     \n",
       "[20,] 286              3.190635     \n",
       "[21,] 281              3.181345     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_order=order(bootstrap_residual_stats$mean)\n",
    "res_bootstrap=sapply(no_rows_sequence,fr)\n",
    "cbind(no_rows_sequence,res_bootstrap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there is a sharp decrease in the MAE in the testing after removing some specific rows in the training dataset according to the inforation achieved during model bootstrap. Best results seem to appear when 20 rows are removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Row selection according to standard methods of multivariate outlier detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Usually, outlier detection is performed through exhausitve EDA through e.g. PCA methods or analysis between variables.\n",
    "\n",
    "* There are some methods to analyze distances between rows and distances from a reference. With these methods, one can find rows behaving as outliers which should be removed from the dataset. We will try to detect rows rto remove throug hthe Mahalanobis distance and the mean KNN distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding of training_data and removal of highly correlated features (which would distort the distance data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_onehot_BostonHousing=scale(predict(onehot::onehot(BostonHousing[train_ind,]),BostonHousing[train_ind,]))\n",
    "highlyCorrelated=findCorrelation(abs(cor(scaled_onehot_BostonHousing)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Calculation of mean distance from 10 nearest neighbors.\n",
    "2. Ordering of rows depending on mean KNN distance.\n",
    "3. Calculation of MAE in test split depending on number of rows selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
       " 0.6578  1.0080  1.3051  1.5032  1.6770  7.2843 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample10: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample15: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
      "\"There were missing values in resampled performance measures.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample02: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample07: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample18: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
      "\"There were missing values in resampled performance measures.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample03: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample05: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample09: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample12: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample13: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample16: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample20: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
      "\"There were missing values in resampled performance measures.\""
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>no_rows_sequence</th><th scope=col>res_knn</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>381     </td><td>3.416829</td></tr>\n",
       "\t<tr><td>376     </td><td>3.475625</td></tr>\n",
       "\t<tr><td>371     </td><td>3.416170</td></tr>\n",
       "\t<tr><td>366     </td><td>3.213418</td></tr>\n",
       "\t<tr><td>361     </td><td>3.268428</td></tr>\n",
       "\t<tr><td>356     </td><td>3.291295</td></tr>\n",
       "\t<tr><td>351     </td><td>3.196163</td></tr>\n",
       "\t<tr><td>346     </td><td>3.165573</td></tr>\n",
       "\t<tr><td>341     </td><td>3.205642</td></tr>\n",
       "\t<tr><td>336     </td><td>3.235552</td></tr>\n",
       "\t<tr><td>331     </td><td>3.340914</td></tr>\n",
       "\t<tr><td>326     </td><td>3.346290</td></tr>\n",
       "\t<tr><td>321     </td><td>3.312502</td></tr>\n",
       "\t<tr><td>316     </td><td>3.282141</td></tr>\n",
       "\t<tr><td>311     </td><td>3.431416</td></tr>\n",
       "\t<tr><td>306     </td><td>3.403803</td></tr>\n",
       "\t<tr><td>301     </td><td>3.404091</td></tr>\n",
       "\t<tr><td>296     </td><td>3.395135</td></tr>\n",
       "\t<tr><td>291     </td><td>3.508065</td></tr>\n",
       "\t<tr><td>286     </td><td>3.511814</td></tr>\n",
       "\t<tr><td>281     </td><td>3.489136</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{ll}\n",
       " no\\_rows\\_sequence & res\\_knn\\\\\n",
       "\\hline\n",
       "\t 381      & 3.416829\\\\\n",
       "\t 376      & 3.475625\\\\\n",
       "\t 371      & 3.416170\\\\\n",
       "\t 366      & 3.213418\\\\\n",
       "\t 361      & 3.268428\\\\\n",
       "\t 356      & 3.291295\\\\\n",
       "\t 351      & 3.196163\\\\\n",
       "\t 346      & 3.165573\\\\\n",
       "\t 341      & 3.205642\\\\\n",
       "\t 336      & 3.235552\\\\\n",
       "\t 331      & 3.340914\\\\\n",
       "\t 326      & 3.346290\\\\\n",
       "\t 321      & 3.312502\\\\\n",
       "\t 316      & 3.282141\\\\\n",
       "\t 311      & 3.431416\\\\\n",
       "\t 306      & 3.403803\\\\\n",
       "\t 301      & 3.404091\\\\\n",
       "\t 296      & 3.395135\\\\\n",
       "\t 291      & 3.508065\\\\\n",
       "\t 286      & 3.511814\\\\\n",
       "\t 281      & 3.489136\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "no_rows_sequence | res_knn | \n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 381      | 3.416829 | \n",
       "| 376      | 3.475625 | \n",
       "| 371      | 3.416170 | \n",
       "| 366      | 3.213418 | \n",
       "| 361      | 3.268428 | \n",
       "| 356      | 3.291295 | \n",
       "| 351      | 3.196163 | \n",
       "| 346      | 3.165573 | \n",
       "| 341      | 3.205642 | \n",
       "| 336      | 3.235552 | \n",
       "| 331      | 3.340914 | \n",
       "| 326      | 3.346290 | \n",
       "| 321      | 3.312502 | \n",
       "| 316      | 3.282141 | \n",
       "| 311      | 3.431416 | \n",
       "| 306      | 3.403803 | \n",
       "| 301      | 3.404091 | \n",
       "| 296      | 3.395135 | \n",
       "| 291      | 3.508065 | \n",
       "| 286      | 3.511814 | \n",
       "| 281      | 3.489136 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "      no_rows_sequence res_knn \n",
       " [1,] 381              3.416829\n",
       " [2,] 376              3.475625\n",
       " [3,] 371              3.416170\n",
       " [4,] 366              3.213418\n",
       " [5,] 361              3.268428\n",
       " [6,] 356              3.291295\n",
       " [7,] 351              3.196163\n",
       " [8,] 346              3.165573\n",
       " [9,] 341              3.205642\n",
       "[10,] 336              3.235552\n",
       "[11,] 331              3.340914\n",
       "[12,] 326              3.346290\n",
       "[13,] 321              3.312502\n",
       "[14,] 316              3.282141\n",
       "[15,] 311              3.431416\n",
       "[16,] 306              3.403803\n",
       "[17,] 301              3.404091\n",
       "[18,] 296              3.395135\n",
       "[19,] 291              3.508065\n",
       "[20,] 286              3.511814\n",
       "[21,] 281              3.489136"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_knn_10_dist=rowMeans(FNN::knn.dist(scaled_onehot_BostonHousing[,-highlyCorrelated]))\n",
    "summary(mean_knn_10_dist)\n",
    "\n",
    "error_order=order(mean_knn_10_dist)\n",
    "res_knn=sapply(no_rows_sequence,fr)\n",
    "cbind(no_rows_sequence,res_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Calculation of Mahalanobis distance.\n",
    "2. Ordering of rows depending on Mahalanobis distance.\n",
    "3. Calculation of MAE in test split depending on number of rows selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
       "  1.394   6.371  10.176  12.966  15.851 157.546 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample23: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
      "\"There were missing values in resampled performance measures.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample07: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
      "\"There were missing values in resampled performance measures.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample07: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample16: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample17: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample18: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample22: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample25: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
      "\"There were missing values in resampled performance measures.\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample01: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample05: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample06: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample08: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample10: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample11: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample12: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample13: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample19: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample22: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample23: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample24: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
      "\"There were missing values in resampled performance measures.\""
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>no_rows_sequence</th><th scope=col>res_mahal</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>381     </td><td>3.397312</td></tr>\n",
       "\t<tr><td>376     </td><td>3.387903</td></tr>\n",
       "\t<tr><td>371     </td><td>3.406490</td></tr>\n",
       "\t<tr><td>366     </td><td>3.431668</td></tr>\n",
       "\t<tr><td>361     </td><td>3.416153</td></tr>\n",
       "\t<tr><td>356     </td><td>3.356433</td></tr>\n",
       "\t<tr><td>351     </td><td>3.334941</td></tr>\n",
       "\t<tr><td>346     </td><td>3.228793</td></tr>\n",
       "\t<tr><td>341     </td><td>3.232468</td></tr>\n",
       "\t<tr><td>336     </td><td>3.261373</td></tr>\n",
       "\t<tr><td>331     </td><td>3.212438</td></tr>\n",
       "\t<tr><td>326     </td><td>3.187449</td></tr>\n",
       "\t<tr><td>321     </td><td>3.210632</td></tr>\n",
       "\t<tr><td>316     </td><td>3.231119</td></tr>\n",
       "\t<tr><td>311     </td><td>3.272586</td></tr>\n",
       "\t<tr><td>306     </td><td>3.249175</td></tr>\n",
       "\t<tr><td>301     </td><td>3.270613</td></tr>\n",
       "\t<tr><td>296     </td><td>3.222871</td></tr>\n",
       "\t<tr><td>291     </td><td>3.229414</td></tr>\n",
       "\t<tr><td>286     </td><td>3.314964</td></tr>\n",
       "\t<tr><td>281     </td><td>3.288885</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{ll}\n",
       " no\\_rows\\_sequence & res\\_mahal\\\\\n",
       "\\hline\n",
       "\t 381      & 3.397312\\\\\n",
       "\t 376      & 3.387903\\\\\n",
       "\t 371      & 3.406490\\\\\n",
       "\t 366      & 3.431668\\\\\n",
       "\t 361      & 3.416153\\\\\n",
       "\t 356      & 3.356433\\\\\n",
       "\t 351      & 3.334941\\\\\n",
       "\t 346      & 3.228793\\\\\n",
       "\t 341      & 3.232468\\\\\n",
       "\t 336      & 3.261373\\\\\n",
       "\t 331      & 3.212438\\\\\n",
       "\t 326      & 3.187449\\\\\n",
       "\t 321      & 3.210632\\\\\n",
       "\t 316      & 3.231119\\\\\n",
       "\t 311      & 3.272586\\\\\n",
       "\t 306      & 3.249175\\\\\n",
       "\t 301      & 3.270613\\\\\n",
       "\t 296      & 3.222871\\\\\n",
       "\t 291      & 3.229414\\\\\n",
       "\t 286      & 3.314964\\\\\n",
       "\t 281      & 3.288885\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "no_rows_sequence | res_mahal | \n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 381      | 3.397312 | \n",
       "| 376      | 3.387903 | \n",
       "| 371      | 3.406490 | \n",
       "| 366      | 3.431668 | \n",
       "| 361      | 3.416153 | \n",
       "| 356      | 3.356433 | \n",
       "| 351      | 3.334941 | \n",
       "| 346      | 3.228793 | \n",
       "| 341      | 3.232468 | \n",
       "| 336      | 3.261373 | \n",
       "| 331      | 3.212438 | \n",
       "| 326      | 3.187449 | \n",
       "| 321      | 3.210632 | \n",
       "| 316      | 3.231119 | \n",
       "| 311      | 3.272586 | \n",
       "| 306      | 3.249175 | \n",
       "| 301      | 3.270613 | \n",
       "| 296      | 3.222871 | \n",
       "| 291      | 3.229414 | \n",
       "| 286      | 3.314964 | \n",
       "| 281      | 3.288885 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "      no_rows_sequence res_mahal\n",
       " [1,] 381              3.397312 \n",
       " [2,] 376              3.387903 \n",
       " [3,] 371              3.406490 \n",
       " [4,] 366              3.431668 \n",
       " [5,] 361              3.416153 \n",
       " [6,] 356              3.356433 \n",
       " [7,] 351              3.334941 \n",
       " [8,] 346              3.228793 \n",
       " [9,] 341              3.232468 \n",
       "[10,] 336              3.261373 \n",
       "[11,] 331              3.212438 \n",
       "[12,] 326              3.187449 \n",
       "[13,] 321              3.210632 \n",
       "[14,] 316              3.231119 \n",
       "[15,] 311              3.272586 \n",
       "[16,] 306              3.249175 \n",
       "[17,] 301              3.270613 \n",
       "[18,] 296              3.222871 \n",
       "[19,] 291              3.229414 \n",
       "[20,] 286              3.314964 \n",
       "[21,] 281              3.288885 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mahal_dist <- mahalanobis(scaled_onehot_BostonHousing[,-highlyCorrelated],\n",
    "                          colMeans(scaled_onehot_BostonHousing[,-highlyCorrelated]),\n",
    "                          cov= var(scaled_onehot_BostonHousing[,-highlyCorrelated]))\n",
    "summary(mahal_dist)\n",
    "\n",
    "\n",
    "error_order=order(mahal_dist)\n",
    "res_mahal=sapply(no_rows_sequence,fr)\n",
    "cbind(no_rows_sequence,res_mahal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Row selection according to residuals in prediction of training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Lastly, we will evaluate if the residuals found during model training would be good enough to help identify rows which should be removed. If performance is worse than with other methods, it will be an indicator that there is some overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Ordering of rows depending on residuals.\n",
    "2. Calculation of MAE in test split depending on number of rows selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n",
       " 0.01018  0.90045  2.23676  3.25370  4.45521 26.93539 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>no_rows_sequence</th><th scope=col>res_residuals</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>381     </td><td>3.397312</td></tr>\n",
       "\t<tr><td>376     </td><td>3.292641</td></tr>\n",
       "\t<tr><td>371     </td><td>3.330818</td></tr>\n",
       "\t<tr><td>366     </td><td>3.300832</td></tr>\n",
       "\t<tr><td>361     </td><td>3.248493</td></tr>\n",
       "\t<tr><td>356     </td><td>3.276811</td></tr>\n",
       "\t<tr><td>351     </td><td>3.290667</td></tr>\n",
       "\t<tr><td>346     </td><td>3.275042</td></tr>\n",
       "\t<tr><td>341     </td><td>3.274659</td></tr>\n",
       "\t<tr><td>336     </td><td>3.304590</td></tr>\n",
       "\t<tr><td>331     </td><td>3.302504</td></tr>\n",
       "\t<tr><td>326     </td><td>3.287129</td></tr>\n",
       "\t<tr><td>321     </td><td>3.286234</td></tr>\n",
       "\t<tr><td>316     </td><td>3.231515</td></tr>\n",
       "\t<tr><td>311     </td><td>3.312345</td></tr>\n",
       "\t<tr><td>306     </td><td>3.278892</td></tr>\n",
       "\t<tr><td>301     </td><td>3.314710</td></tr>\n",
       "\t<tr><td>296     </td><td>3.289429</td></tr>\n",
       "\t<tr><td>291     </td><td>3.313655</td></tr>\n",
       "\t<tr><td>286     </td><td>3.340961</td></tr>\n",
       "\t<tr><td>281     </td><td>3.326504</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{ll}\n",
       " no\\_rows\\_sequence & res\\_residuals\\\\\n",
       "\\hline\n",
       "\t 381      & 3.397312\\\\\n",
       "\t 376      & 3.292641\\\\\n",
       "\t 371      & 3.330818\\\\\n",
       "\t 366      & 3.300832\\\\\n",
       "\t 361      & 3.248493\\\\\n",
       "\t 356      & 3.276811\\\\\n",
       "\t 351      & 3.290667\\\\\n",
       "\t 346      & 3.275042\\\\\n",
       "\t 341      & 3.274659\\\\\n",
       "\t 336      & 3.304590\\\\\n",
       "\t 331      & 3.302504\\\\\n",
       "\t 326      & 3.287129\\\\\n",
       "\t 321      & 3.286234\\\\\n",
       "\t 316      & 3.231515\\\\\n",
       "\t 311      & 3.312345\\\\\n",
       "\t 306      & 3.278892\\\\\n",
       "\t 301      & 3.314710\\\\\n",
       "\t 296      & 3.289429\\\\\n",
       "\t 291      & 3.313655\\\\\n",
       "\t 286      & 3.340961\\\\\n",
       "\t 281      & 3.326504\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "no_rows_sequence | res_residuals | \n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 381      | 3.397312 | \n",
       "| 376      | 3.292641 | \n",
       "| 371      | 3.330818 | \n",
       "| 366      | 3.300832 | \n",
       "| 361      | 3.248493 | \n",
       "| 356      | 3.276811 | \n",
       "| 351      | 3.290667 | \n",
       "| 346      | 3.275042 | \n",
       "| 341      | 3.274659 | \n",
       "| 336      | 3.304590 | \n",
       "| 331      | 3.302504 | \n",
       "| 326      | 3.287129 | \n",
       "| 321      | 3.286234 | \n",
       "| 316      | 3.231515 | \n",
       "| 311      | 3.312345 | \n",
       "| 306      | 3.278892 | \n",
       "| 301      | 3.314710 | \n",
       "| 296      | 3.289429 | \n",
       "| 291      | 3.313655 | \n",
       "| 286      | 3.340961 | \n",
       "| 281      | 3.326504 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "      no_rows_sequence res_residuals\n",
       " [1,] 381              3.397312     \n",
       " [2,] 376              3.292641     \n",
       " [3,] 371              3.330818     \n",
       " [4,] 366              3.300832     \n",
       " [5,] 361              3.248493     \n",
       " [6,] 356              3.276811     \n",
       " [7,] 351              3.290667     \n",
       " [8,] 346              3.275042     \n",
       " [9,] 341              3.274659     \n",
       "[10,] 336              3.304590     \n",
       "[11,] 331              3.302504     \n",
       "[12,] 326              3.287129     \n",
       "[13,] 321              3.286234     \n",
       "[14,] 316              3.231515     \n",
       "[15,] 311              3.312345     \n",
       "[16,] 306              3.278892     \n",
       "[17,] 301              3.314710     \n",
       "[18,] 296              3.289429     \n",
       "[19,] 291              3.313655     \n",
       "[20,] 286              3.340961     \n",
       "[21,] 281              3.326504     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(abs(predict(model,BostonHousing[train_ind,])-BostonHousing$medv[train_ind]))\n",
    "\n",
    "error_order=order(abs(predict(model,BostonHousing[train_ind,])-BostonHousing$medv[train_ind]))\n",
    "res_residuals=sapply(no_rows_sequence,fr)\n",
    "cbind(no_rows_sequence,res_residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now, we compare results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data.frame(nrows=no_rows_sequence,bootstrap=res_bootstrap,KNN=res_knn,Mahalanobis=res_mahal,residual=res_residuals)\n",
    "df=reshape2::melt(df,id='nrows')\n",
    "names(df)=c(\"nrows\",\"method\",\"MAE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAARVBMVEUAAAAAv8QzMzNNTU1o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\nEAAiASDA/wEwdi2ZgCOc8wAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p=ggplot(df, aes(x=nrows, y=MAE, color=method)) +geom_line()+\n",
    "  labs(title=\"Relationship between MAE and selected rows\",\n",
    "        x =\"Selected rows\", y = \"MAE\")\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We can see that the row selection based on information achieved during bootstrapping achieves the best results.\n",
    "\n",
    "*Row selection based on residuals shows much worse performance in testing data. This is an indicator that there is some overfitting of noise during model training and the model is trying to accurately fit noisy rows.\n",
    "\n",
    "*Row selection based on KNN also achieves good results. However, the trend is much more inconsistent. We should take into account that model training should not be based on test data information so the selection of rows should be based on rows behaving as outliers. The selection of the number of rows to remove should be based on applying methods such as the function outlier.stats. These methods will give worse performance with inconsistent trends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the mean bootstrap_residual_stats which behave as outliers and see how the difference between the MAE with all rows and the selected rows is reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=white-space:pre-wrap>'Rows selected:  348'</span>"
      ],
      "text/latex": [
       "'Rows selected:  348'"
      ],
      "text/markdown": [
       "<span style=white-space:pre-wrap>'Rows selected:  348'</span>"
      ],
      "text/plain": [
       "[1] \"Rows selected:  348\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'MAE with all rows: 3.4357095034663'"
      ],
      "text/latex": [
       "'MAE with all rows: 3.4357095034663'"
      ],
      "text/markdown": [
       "'MAE with all rows: 3.4357095034663'"
      ],
      "text/plain": [
       "[1] \"MAE with all rows: 3.4357095034663\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'MAE with selected rows: 3.18017772252628'"
      ],
      "text/latex": [
       "'MAE with selected rows: 3.18017772252628'"
      ],
      "text/markdown": [
       "'MAE with selected rows: 3.18017772252628'"
      ],
      "text/plain": [
       "[1] \"MAE with selected rows: 3.18017772252628\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'% decrease -7.43752580601519'"
      ],
      "text/latex": [
       "'\\% decrease -7.43752580601519'"
      ],
      "text/markdown": [
       "'% decrease -7.43752580601519'"
      ],
      "text/plain": [
       "[1] \"% decrease -7.43752580601519\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "row_number_to_keep=length(which(bootstrap_residual_stats$mean<=boxplot.stats(bootstrap_residual_stats$mean)$stats[5]))\n",
    "paste(\"Rows selected: \",row_number_to_keep)\n",
    "error_order=order(bootstrap_residual_stats$mean)\n",
    "MAE_all_rows=fr(no_rows_sequence[1])\n",
    "MAE_selected_rows=fr(row_number_to_keep)\n",
    "paste(\"MAE with all rows:\",MAE_all_rows)\n",
    "paste(\"MAE with selected rows:\",MAE_selected_rows)\n",
    "paste(\"% decrease\",100*(MAE_selected_rows/MAE_all_rows-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have reduced the error 7% without the need of fancy computationally intensive algorithms or of exhaustive post-hoc and data dredging prone analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Row selection in test data (yeah, really)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems we have reduced a 7% the error during prediction thanks to being able to detect which rows add noise to be overfit and create non-generalizable information.\n",
    "\n",
    "Ok, let's stop a moment and think about what it means to have found rows to remove in the training data: it means that we also have error in the test data which is distorting our evaluation of the quality of our model. Our model would be better predicting than we are aware of.\n",
    "\n",
    "How to find te noise in the test data? Well, we can do the same process than with the training data: we can carete a model during bootstrapping and evaluate which rows gave higher error during the iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample0004: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample0177: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample0348: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample0420: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample0676: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample0687: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample0935: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample0946: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
      "\"There were missing values in resampled performance measures.\""
     ]
    },
    {
     "data": {
      "text/plain": [
       "The lasso \n",
       "\n",
       "125 samples\n",
       " 13 predictor\n",
       "\n",
       "Pre-processing: centered (13), scaled (13) \n",
       "Resampling: Bootstrapped (1000 reps) \n",
       "Summary of sample sizes: 125, 125, 125, 125, 125, 125, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  fraction   RMSE      Rsquared   MAE     \n",
       "  0.1000000  6.859995  0.6156227  5.167117\n",
       "  0.1888889  5.757482  0.6443806  4.446365\n",
       "  0.2777778  5.078655  0.6822006  3.926126\n",
       "  0.3666667  4.794751  0.6992375  3.664107\n",
       "  0.4555556  4.668190  0.7135033  3.568376\n",
       "  0.5444444  4.594756  0.7213405  3.507981\n",
       "  0.6333333  4.554275  0.7259424  3.470836\n",
       "  0.7222222  4.528801  0.7288102  3.443660\n",
       "  0.8111111  4.516695  0.7302756  3.428913\n",
       "  0.9000000  4.519535  0.7303300  3.424980\n",
       "\n",
       "MAE was used to select the optimal model using the smallest value.\n",
       "The final value used for the model was fraction = 0.9."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(1);test_model <- train(medv ~ . ,\n",
    "               data = BostonHousing[-train_ind,],\n",
    "               preProcess = c(\"center\", \"scale\"),\n",
    "               method = \"lasso\",\n",
    "               metric=\"MAE\",\n",
    "               tuneLength = 10,\n",
    "               trControl = trainControl(method = \"boot632\",number=1000,\n",
    "                                        savePredictions = \"all\"))\n",
    "test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    rowIndex        mean               sd        \n",
       " Min.   :  1   Min.   : 0.7316   Min.   :0.5397  \n",
       " 1st Qu.: 32   1st Qu.: 2.0397   1st Qu.:1.2014  \n",
       " Median : 63   Median : 3.0429   Median :1.6483  \n",
       " Mean   : 63   Mean   : 3.9644   Mean   :1.8561  \n",
       " 3rd Qu.: 94   3rd Qu.: 4.9867   3rd Qu.:2.2033  \n",
       " Max.   :125   Max.   :13.9014   Max.   :5.2844  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_model$pred$MAE=abs(test_model$pred$pred-test_model$pred$obs)\n",
    "\n",
    "test_bootstrap_residual_stats = test_model$pred %>%\n",
    "group_by(rowIndex) %>%\n",
    "summarise(mean = mean(MAE,na.rm=T),sd=sd(MAE,na.rm=T))\n",
    "summary(test_bootstrap_residual_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can evaluate if row selection  in the test dataset based on removing the rows with worse error can improve the results in the training dataset (we retrain 'test_model' to ensure the number of bootstrap iterations does not play a role):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=white-space:pre-wrap>'Rows selected:  116'</span>"
      ],
      "text/latex": [
       "'Rows selected:  116'"
      ],
      "text/markdown": [
       "<span style=white-space:pre-wrap>'Rows selected:  116'</span>"
      ],
      "text/plain": [
       "[1] \"Rows selected:  116\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in preProcess.default(thresh = 0.95, k = 5, freqCut = 19, uniqueCut = 10, :\n",
      "\"These variables have zero variances: chas1\"Warning message:\n",
      "\"model fit failed for Resample04: fraction=0.9 Error in elasticnet::enet(as.matrix(x), y, lambda = 0, ...) : \n",
      "  Some of the columns of x have zero variance\n",
      "\"Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
      "\"There were missing values in resampled performance measures.\""
     ]
    },
    {
     "data": {
      "text/html": [
       "'MAE with all rows: 3.56474294446306'"
      ],
      "text/latex": [
       "'MAE with all rows: 3.56474294446306'"
      ],
      "text/markdown": [
       "'MAE with all rows: 3.56474294446306'"
      ],
      "text/plain": [
       "[1] \"MAE with all rows: 3.56474294446306\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'MAE with all selected: 3.44976003143164'"
      ],
      "text/latex": [
       "'MAE with all selected: 3.44976003143164'"
      ],
      "text/markdown": [
       "'MAE with all selected: 3.44976003143164'"
      ],
      "text/plain": [
       "[1] \"MAE with all selected: 3.44976003143164\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'% decrease -3.22555973383768'"
      ],
      "text/latex": [
       "'\\% decrease -3.22555973383768'"
      ],
      "text/markdown": [
       "'% decrease -3.22555973383768'"
      ],
      "text/plain": [
       "[1] \"% decrease -3.22555973383768\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx_to_keep=which(new_bootstrap_residual_stats$mean<=boxplot.stats(new_bootstrap_residual_stats$mean)$stats[5])\n",
    "paste(\"Rows selected: \",length(idx_to_keep))\n",
    "\n",
    "set.seed(1);test_model=train(medv ~ . ,\n",
    "                             data = BostonHousing[-train_ind,],\n",
    "                             preProcess = c(\"center\", \"scale\"),\n",
    "                             method = \"lasso\",\n",
    "                             metric=\"MAE\",\n",
    "                             tuneLength = 10,\n",
    "                             trControl = trainControl(method = \"boot632\",\n",
    "                                                      savePredictions = \"all\"))\n",
    "\n",
    "dummy=MAE(pred = predict(test_model,BostonHousing[train_ind,]),obs=BostonHousing$medv[train_ind])\n",
    "paste(\"MAE with all rows:\",dummy)\n",
    "set.seed(1);test_model_2=train(medv ~ . ,\n",
    "                             data = BostonHousing[-train_ind,][idx_to_keep,],\n",
    "                             preProcess = c(\"center\", \"scale\"),\n",
    "                             method = \"lasso\",\n",
    "                             metric=\"MAE\",\n",
    "                             tuneLength = 10,\n",
    "                             trControl = trainControl(method = \"boot632\",\n",
    "                                                      savePredictions = \"all\"))\n",
    "dummy2=MAE(pred = predict(test_model_2,BostonHousing[train_ind,]),obs=BostonHousing$medv[train_ind])\n",
    "paste(\"MAE with all selected:\",dummy2)\n",
    "\n",
    "paste(\"% decrease\",100*(dummy2/dummy-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have checked that the row selection in the test dataset increases the quality of this dataset, we can used the edited test dataset to evaluate the actual improvement of the model after performing row selection in the training and the test datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'MAE with all rows: 3.4357095034663'"
      ],
      "text/latex": [
       "'MAE with all rows: 3.4357095034663'"
      ],
      "text/markdown": [
       "'MAE with all rows: 3.4357095034663'"
      ],
      "text/plain": [
       "[1] \"MAE with all rows: 3.4357095034663\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'MAE with selected rows: 2.54389271794976'"
      ],
      "text/latex": [
       "'MAE with selected rows: 2.54389271794976'"
      ],
      "text/markdown": [
       "'MAE with selected rows: 2.54389271794976'"
      ],
      "text/plain": [
       "[1] \"MAE with selected rows: 2.54389271794976\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'% decrease -25.9572814470137'"
      ],
      "text/latex": [
       "'\\% decrease -25.9572814470137'"
      ],
      "text/markdown": [
       "'% decrease -25.9572814470137'"
      ],
      "text/plain": [
       "[1] \"% decrease -25.9572814470137\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paste(\"MAE with all rows:\",MAE_all_rows)\n",
    "MAE_selected_train_test=rows=MAE(pred = predict(new_model,BostonHousing[-train_ind,][idx_to_keep,]),obs=BostonHousing$medv[-train_ind][idx_to_keep])\n",
    "\n",
    "paste(\"MAE with selected rows:\",MAE_selected_train_test)\n",
    "paste(\"% decrease\",100*(MAE_selected_train_test/MAE_all_rows-1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, so only performing only a few easy automatics teps of row selection we have reduced the error more than 25%!\n",
    "\n",
    "Well, conceptually, I think the improvement is not that high. The initial model was never that bad but its quality was hidden by the noise in the test dataset. A more accurate estimation of the decrease error achieved after row selection requires comparing results with the test dataset after row selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'MAE with all rows: 2.82632981119992'"
      ],
      "text/latex": [
       "'MAE with all rows: 2.82632981119992'"
      ],
      "text/markdown": [
       "'MAE with all rows: 2.82632981119992'"
      ],
      "text/plain": [
       "[1] \"MAE with all rows: 2.82632981119992\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'MAE with selected rows: 2.54389271794976'"
      ],
      "text/latex": [
       "'MAE with selected rows: 2.54389271794976'"
      ],
      "text/markdown": [
       "'MAE with selected rows: 2.54389271794976'"
      ],
      "text/plain": [
       "[1] \"MAE with selected rows: 2.54389271794976\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'% decrease -9.99306917865537'"
      ],
      "text/latex": [
       "'\\% decrease -9.99306917865537'"
      ],
      "text/markdown": [
       "'% decrease -9.99306917865537'"
      ],
      "text/plain": [
       "[1] \"% decrease -9.99306917865537\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAE_selected_test=rows=MAE(pred = predict(model,BostonHousing[-train_ind,][idx_to_keep,]),obs=BostonHousing$medv[-train_ind][idx_to_keep])\n",
    "\n",
    "paste(\"MAE with all rows:\",MAE_selected_test)\n",
    "MAE_selected_train_test=rows=MAE(pred = predict(new_model,BostonHousing[-train_ind,][idx_to_keep,]),obs=BostonHousing$medv[-train_ind][idx_to_keep])\n",
    "\n",
    "paste(\"MAE with selected rows:\",MAE_selected_train_test)\n",
    "paste(\"% decrease\",100*(MAE_selected_train_test/MAE_selected_test-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have achieved an actual 10% decrease in the error thanks to the automatic row selection method applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Theoretically, this row selection method should be easily applied for classification models through the evaluation of the confusion matrix for each row.\n",
    "\n",
    "*This approach seems especially promising for non-tabular or highly categorical datasets. Typical methods to evaluate outliers are based on numeric approaches which are not easy to translate to this kinds of datasets.\n",
    "\n",
    "*Image or NLP problems, where a huge amount of time might need to be spent labeling correctly the datasets, might be hugely benefited by this kind of approach. Semisupervised approaches to expand datasets consist of using a small correctly labelled  dataset to predict the label in a huge dataset so to expand the dataset to be used during model training. However, these approaches have the tradeoff of adding noise to the dataset through wrong labelling during prediction. Performing image selection based on wrong labelling during bootstrapped modelling in the training dataset might help achieve much more generalizable models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
